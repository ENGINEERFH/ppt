# ppt
DeepFace：在面部验证中缩小与人类级别的差距
在现代人脸识别中，传统的管道包括四个阶段：检测⇒对齐⇒代表⇒分类。我们通过采用显式3D人脸建模来重新考虑对齐步骤和表示步骤，以便应用分段仿射变换，并从九层深度神经网络导出人脸表示。这个深度网络涉及超过1.2亿个参数，使用几个没有权重共享的本地连接层，而不是标准的卷积层。因此，我们在迄今为止最大的面部数据集上训练它，这是一个标识四百万个面部图像的数据集，属于超过4,000个身份。即使使用简单的分类器，将精确的基于模型的对齐与大型面部数据库耦合的学习表示也非常好地概括为无约束环境中的面部。我们的方法在野外标记面（LFW）数据集中达到了97.35％的准确度，将当前技术水平的误差减少了27％以上，接近人类水平的表现。
简介
无约束图像中的人脸识别处于算法感知革命的最前沿。人脸识别技术的社会和文化影响是深远的，但目前机器与人类视觉系统之间在这一领域的性能差距可以作为缓解这些影响的缓冲。
我们提出了一个系统（DeepFace），该系统在无约束人脸识别中已经关闭了最受欢迎基准测试中的大部分剩余差距，现在处于人类水平准确度的边缘。它是根据从用于构建评估基准的人群中获得的大量人脸获得的大型数据集进行培训，并且能够以非常小的适应性优于现有系统。此外，该系统产生极其紧凑的面部表示，与移位形成鲜明对比
1
在其他最近的系统中，成千上万的外观特征[5,7,2]。
所提出的系统与该领域的大多数贡献的不同之处在于它使用深度学习（DL）框架[3,21]代替精心设计的特征。 DL特别适用于处理大型训练集，最近在视觉，语音和语言建模等不同领域取得了许多成功。特别是对于面部，学习网络以稳健方式捕获面部外观的成功高度依赖于非常快速的3D对准步骤。网络架构基于这样的假设：一旦对准完成，每个面部区域的位置固定在像素级。因此，可以从原始像素RGB值中学习，而不需要像在许多其他网络中那样应用几层卷积[19,21]。
总之，我们做出以下贡献：（i）开发有效的深度神经网络（DNN）架构和学习方法，利用非常大的面部标记数据集，以获得能够很好地推广到其他数据集的面部表示; （ii）基于面部显式三维建模的有效面部对齐系统; （iii）在（1）野性标记面（LFW）[18]中显着提升现有技术水平，达到接近人类的表现; （2）YouTube Faces数据集（YTF）[30]，将错误率降低50％以上。

4.验证指标
验证两个输入实例是否属于同一类（同一性），在无约束人脸识别领域进行了广泛研究，监督方法显示出明显的性能优于无人监督的方法。通过训练目标域的训练集，可以微调特征向量（或分类器）以在数据集的特定分布内更好地执行。例如，LFW有大约75％的男性，大多数专业摄影师拍摄的名人。如[5]所示，不同域分布内的训练和测试会严重影响性能，并需要进一步调整表示（或分类器）以改进其泛化和性能。但是，将模型拟合到相对较小的数据集会减少其对其他数据集的推广。在这项工作中，我们的目标是学习一个无监督的度量，它可以很好地推广到几个数据集。我们的无监督相似性仅仅是两个归一化特征向量之间的内积。我们还尝试了监督度量，χ2相似性和Siamese network。
4.1。 加权χ2距离
我们方法中的归一化DeepFace特征向量包含与基于直方图的特征的几个相似之处，例如LBP [1] :( 1）它包含非负值，（2）它非常稀疏，（3）它的值介于两者之间 [0,1]。 因此，类似于[1]，我们使用加权-χ2相似性：χ2（f1，f2）= Pi wi（f1 [i] -f2 [i]）2 /（f1 [i] + f2 [i]）其中 f1和f2是DeepFace表示。 使用线性SVM学习权重参数，应用于元素的矢量（f1 [i] -f2 [i]）2 /（f1 [i] + f2 [i]）。
4.2.	Siamese network
我们还测试了端到端度量学习方法，称为Siamese网络[8]：一旦学会了，人脸识别网络（没有顶层）被复制两次（每个输入图像一个），并使用这些功能直接预测两个输入图像是否属于同一个人。这是通过以下方式实现的：a）获取特征之间的绝对差异，然后b）顶部完全连接的层，其映射到单个逻辑单元（相同/不相同）。网络具有与原始网络大致相同数量的参数，因为大部分参数在两个副本之间共享，但需要两倍的计算。请注意，为了防止面部验证任务过度拟合，我们仅对两个最顶层进行培训。暹罗网络的诱导距离为：d（f1，f2）=Piαi| f1 [i] -f2 [i] |，其中αi是可训练参数。通过标准交叉熵损失和误差的反向传播来训练Siamese网络的参数。
5.实验
我们通过在线收集的非常大规模的标记面部数据集学习面部表示来评估所提出的DeepFace系统。 在本节中，我们首先介绍实验中使用的数据集，然后介绍详细的评估和与最新技术的比较，以及关于学习和转移深层表征的一些见解和发现。
5.1。数据集
所提出的面部表示是从来自Facebook的大量照片中学习的，被称为社交面部分类（SFC）数据集。然后将表示应用于Wild数据库中的Labeled Faces（LFW），这是在无约束环境中进行面部验证的事实上的基准数据集，以及YouTube Faces（YTF）数据集，其模拟类似于LFW，但侧重于视频剪辑。
SFC数据集包括来自4,030个人的440万个标记面部，每个面部具有800到1200个面部，其中每个身份的最近5％的面部图像被省略用于测试。这是根据图像的时间戳来完成的，以便通过老化来模拟连续识别。每人大量的图像为学习人脸识别核心问题所需的不变性提供了独特的机会。我们已经使用几种自动方法验证了，通过检查其名称标签，用于训练的身份与下述数据集中的任何身份都不相交。
LFW数据集[18]由5,749名名人的13,323张网络照片组成，这些照片分为10个分组中的6,000个面对。使用A）受限制的协议，通过平均识别准确度来衡量绩效，其中只有相同且不相同的标签可用于培训; B）不受限制的协议，其中可以在培训中获得额外的培训对;和C）无监督设置，其中不对LFW图像执行任何训练。
YTF数据集[30]收集了1,525个主题的1,525个YouTube视频（LFW中的一部分名人）。这些视频分为5,000个视频对和10个分割，用于评估视频级面部验证。
SFC中的面部身份由人类标记，其通常包含约3％的错误。与LFW和YTF中的名人网络图像相比，社交脸部照片在图像质量，照明和表现方面的变化更大，这些图像通常由专业摄影师而非智能手机拍摄。
5.2。 证监会培训
我们首先使用基于GPU的引擎在SFC上训练深度神经网络作为多类分类问题，通过具有动量（设置为0.9）的随机梯度下降（SGD）在前馈网络上实现标准反向传播。我们的小批量大小是128，我们已经为所有可训练层设置了相同的学习率为0.01，手动减少，一旦验证错误停止减少，每次一个数量级，最终速率为0.0001。我们从零均值高斯分布初始化每层中的权重，σ= 0.01，偏差设置为0.5。我们对网络进行了大约15次扫描（时期）的训练，整个数据耗时3天。如第二节所述。如图3所示，提取完全连接层F7的响应以用作面部表示。
我们根据SFC的5％数据作为测试集的分类错误评估了DNN的不同设计选择。这证实了使用大规模人脸数据集和深层架构的必要性。首先，我们通过使用SFC中的人员子集来改变列车/测试数据集的大小。使用大小为1.5K，3K和4K人的子集（分别为1.5M，3.3M和4.4M面）。使用图2中的架构，我们训练了三个网络，用DF-1.5K，DF-3.3K和DF-4.4K表示。表1（左栏）显示，当对3K人进行分类时，分类误差仅从1.5K的7.0％适度增长到7.2％，这表明网络的容量可以很好地适应3M训练图像的规模。对于拥有4.4M图像的4K人来说，错误率上升到8.7％，这表明网络可以让更多人舒适地缩放。我们还将SFC中的全球样本数量改为10％，20％，50％，保留了身份的数量，表中间列为DF-10％，DF-20％，DF-50％。我们观察到测试误差上升到20.7％，因为减少了训练集的过度拟合。由于性能不会在4M图像中饱和，这表明网络将从更大的数据集中受益。
我们还通过切断C3层，两个局部L4和L5层或所有这三个层（分别称为DF-sub1，DF-sub2和DFsub3）来改变网络的深度。例如，与图2中所提出的网络的9层相比，DFsub3中仅剩下四个可训练层，这是一个相当浅的结构。在训练具有4.4M面部的这种网络时，分类错误在几个时期之后停止减少并且仍然存在在高于深层网络的水平，如表1（右栏）所示。这可以验证在大型面部数据集上进行训练时网络深度的必要性。
5.3。 LFW数据集的结果
近年来，视觉界在无约束环境中的面部验证方面取得了重大进展。 LFW [18]的平均识别准确率稳步上升至人类表现超过97.5％[20]。鉴于老化效应导致的一些非常困难的情况，LFW中的大型照明和面部姿势变化，对现有技术的任何改进都是非常显着的，并且系统必须由高度优化的模块组成。返回效应逐渐减弱，现在任何进展都需要大量努力来减少最先进方法的错误数量。 DeepFace将大型基于前馈的模型与精细的3D对齐结合在一起。关于每个组件的重要性：1）没有正面化：当仅使用2D对齐时，获得的准确度“仅”为94.3％。完全没有对齐，即使用面部检测的中心裁剪，准确度为87.9％，因为面部区域的一部分可能从裁剪中掉出来。 2）没有学习：当仅使用正面化和初始LBP / SVM组合时，精度为91.4％，这已经是值得注意的，因为这种分类器的简单性。
所有LFW图像都在用于在SFC数据集上训练的相同管道中处理，表示为DeepFace-single。为了单独评估面部表示的判别能力，我们遵循无监督设置直接比较一对规范化特征的内积。非常显着的是，这实现了95.92％的平均准确度，几乎与迄今为止通过监督转移学习实现的最佳性能相当[5]。接下来，我们在限制协议之后在χ2-距离矢量（第4.1节）之上学习核SVM（具有C = 1），即，每个分裂仅有5,400对标签可用于SVM训练。这实现了97.00％的准确度，显着降低了现有技术的误差[7,5]，见表3
DNN的集合。接下来，我们将通过向DNN提供不同类型的输入而训练的多个网络组合：1）基于3D对齐RGB输入的上述网络DeepFace单个; 2）灰度图像加上图像梯度的大小和方向; 3）2D对齐的RGB图像。我们使用非线性SVM（C = 1）将这些距离与功率CPD内核的简单和相结合：KCombined：= Ksingle + Kgradient + Kalign2d，其中K（x，y）：= - || x - y || 2，遵循限制协议，达到97.15％的准确率。
无限制协议为操作员提供关于训练集中的身份的知识，因此能够生成更多训练集以添加到训练集。我们进一步尝试培训暹罗网络（第4.2节），通过微调Siamese（共享）预训练特征提取器来学习验证指标。按照这个程序，我们观察到对训练数据的实质性过度拟合。使用LFW训练数据生成的训练对是冗余的，因为它们是由大约9K的照片生成的，这不足以可靠地估计超过120M的参数。为了解决这些问题，我们按照与SFC相同的程序收集了一个额外的数据集，其中包含一个额外的新100K标识，每个标识只有30个样本来生成相同和不同的对。然后，我们在其上训练了暹罗网络，接着是关于LFW无限制训练分裂的2个训练时期，以校正一些依赖于数据集的偏差。稍微改进的表示与之前类似地处理。将其组合到上述集合中，即KCombined + = KSiamese，在不受限制的协议下产生97.25％的准确度。通过向整体添加四个额外的DeepFace单网络，每个网络从头开始训练不同的随机种子，即KCombined + = PKDeepFace-Single，获得的准确度为97.35％。组合之前各个网络的性能如表2所示。
在平均准确度和ROC曲线方面与最近的最新方法的比较在表3和图3中给出，包括在裁剪的面部上的人类表现。 提出的DeepFace方法在面部验证中推进了最先进的，接近人类的表现
5.4。 YTF数据集的结果
我们在最近的视频级面部验证数据集上进一步验证了DeepFace。 YouTube视频帧的图像质量通常比网络照片的图像质量差，主要是由于运动模糊或观看距离。我们直接使用DeepFace单一表示，为每对训练视频创建50对帧，每个视频一个，并根据视频训练对将它们标记为相同或不同。然后如第二节中那样学习加权的χ2模型。 4.1。给定一对测试对，我们采样100个随机对帧，每个视频一个，并使用学习加权相似度的平均值。
与最近的方法的比较显示在表4和图4中。我们报告的准确度为91.4％，其将先前最佳方法的误差减少超过50％。请注意，视频对有大约100个错误标签，最近更新到YTF网页。在纠正这些之后，DeepFace-single实际上达到了92.5％。此实验再次验证DeepFace方法可以轻松推广到新的目标域。	
5.5。 计算效率
我们已经有效地实现了一个基于CPU的前馈操作符，它通过利用内核和映像上的浮点计算的位置来利用CPU的单指令多数据（SIMD）指令及其缓存。 使用单核Intel 2.2GHz CPU，操作员需要0.18秒从原始输入像素中提取特征。 采用了有效的翘曲技术进行对齐; 单独对齐大约需要0.05秒。 总的来说，DeepFace每张图像运行0.33秒，考虑到图像解码，面部检测和对齐，前馈网络和最终分类输出。
六，结论
理想的面部分类器将识别仅由人匹配的精确面部。底层面部描述符需要对姿势，光照，表达和图像质量不变。它也应该是一般性的，因为它可以应用于几乎没有任何修改的各种群体，如果有的话。此外，短描述符是优选的，并且如果可能的话，稀疏特征。当然，快速计算时间也是一个问题。我们认为，这项工作偏离了最近使用更多功能和采用更强大的度量学习技术的趋势，已经解决了这一挑战，缩小了绝大多数的性能差距。我们的工作表明，将基于3D模型的对齐与大容量前馈模型耦合可以有效地从许多示例中学习，以克服先前方法的缺点和局限性。在面部识别中呈现显着改善的能力证明了这种耦合在其他视觉领域中变得显着的潜力。
