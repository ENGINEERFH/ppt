在人脸识别领域中开始采用支持大数据集的深度学习方案之后，大规模的人脸数据集开始出现。例如Facebook的Yaniv Taigman等人[1_D]构建了一个拥有四百多万张面部图片的数据集，其中有包含4000多个不同的人，称为SCF。在SCF的助力下，Yaniv Taigman等人训练出了一个接近人类表现的数据集，充分体现了构建大规模人脸数据集的必要性，不过该数据集没有被开源。
之后首先开源大规模人脸数据集的是Dong Yi等人[4_L]，他们构建了一个拥有大约五十万张面部图片的数据集，其中有包含大约10000个不同的人，称为CASIAWebFace。虽然该数据集的面部图片数量比SCF少很多，但是包含的人的数量是SCF的2倍多，这一点使得Dong Yi等人在该数据集上训练出了一个性能和SCF上相当的模型，且模型的设计结构差距不大。从此处可以发现人脸数据集的大不止要体现在面部图片的数量上，还体现在包含的人的数量上。
Dong Yi等人最大的贡献是不仅将CASIAWebFace开源，而且在其论文中详细介绍了一套从互联网中收集大规模人脸数据集的方法[4_L]：先从IMDb网站上抓取一些感兴趣的名人的名字，然后下载他们页面中的照片。其中网页的主图片几乎都是只有一张本人的脸，但是其他的图片可能包含别人的人脸，于是就以主图片上的人脸为种子，通过一套简单快速的聚类方法注释出其他图片中所需的人脸。最后排除掉已被包含在之后训练测试会采用的开源测试集的人去掉。
上述方案提出的从互联网收集人脸数据集方法催生出了很多新的更好的大规模人脸数据集，例如：
	MS-Celeb-1M[]:总共大约一千万张面部图片，其中包含大约100000个不同的人
	VGGFace2[]：总共约三百三十一万张面部图片，其中包含9131个不同的人。
这些数据集包含了丰富的年龄变化，姿态变化，面部表情变化，面部装饰变化和面部遮挡变化。 
