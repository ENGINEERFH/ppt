2.1 相关工作
一直以来，深度学习领域所取得的诸多成就往往都离不开数据集的贡献。数据集一般会被分为三类：训练集、验证集和测试集。这三类数据集的作用分别是：
1)	训练集用于训练模型。
2)	验证集用于调整模型的超参数和选出最优的模型。
3)	测试集用于评估最终模型的泛化能力。
然而人脸识别在实际使用时通常会遇到不包含在训练集中的新身份，这是人脸识别有别于一般深度学习任务最大不同点之一。例如分类任务在实际使用时也只能用于分类出训练集所包含的类别。于是分类任务只需要关注模型在训练集包含的类别上的分类能力，而人脸识别任务更需要关注模型在新身份上的识别能力。由于验证集一般都是从训练集中切分出来且并不包含新的身份，因此在人脸识别的研究中，研究人员基本都只采用训练集和测试集，不会采用验证集，让测试集兼顾验证集的功能，并且使用不包含在训练集中的新身份所对应的面部图片构成测试集。下面将分别概述人脸识别领域中训练集和测试集的相关工作。
2.1.1 训练集
在研究人员开始将能够支持大规模数据集的深度学习方案应用于人脸识别之后，大规模的人脸数据集开始出现。例如Facebook的Yaniv Taigman等人[1_D]构建了一个拥有四百多万张面部图片的数据集(SCF)，其中有包含4000多个不同的身份。在SCF的助力下，Yaniv Taigman等人训练出了一个接近人类表现的人脸识别模型，充分体现了构建大规模人脸数据集的必要性，不过该数据集没有被开源。
之后首先开源大规模人脸数据集的是Dong Yi等人[4_L]，他们构建了一个拥有大约五十万张面部图片的数据集(CASIA WebFace)，其中有包含大约10000个不同的身份。虽然该数据集的面部图片数量比SCF少很多，但是包含的身份数量是SCF的2倍多，这一点使得Dong Yi等人在该数据集上训练出了一个性能和SCF上相当的模型，且模型的设计结构差距不大。从此处可以发现人脸数据集的大不止要体现在面部图片的数量上，还体现在包含的身份数量上。
Dong Yi等人最大的贡献是不仅将CASIAWebFace开源，而且在其论文中详细介绍了一套从互联网中收集大规模人脸数据集的方法[4_L]：先从IMDb网站上抓取一些感兴趣的名人的名字，然后下载他们页面中的照片。其中网页的主图片几乎都是只有一张本人的脸，但是其他的图片可能包含别人的人脸，于是就以主图片上的人脸为种子，通过一套简单快速的聚类方法注释出其他图片中所需的人脸。最后将测试集包含的身份所对应的面部图片去掉。
上述方案提出的从互联网收集人脸数据集方法催生出了很多新的更好的大规模人脸数据集，例如：
	MS-Celeb-1M[]:总共大约一千万张面部图片，其中包含大约100000个不同的身份
	VGGFace2[]：总共约三百三十一万张面部图片，其中包含9131个不同的身份。
2.1.2 测试集


这些数据集包含了丰富的年龄变化，姿态变化，面部表情变化，面部装饰变化和面部遮挡变化。 
如今，身份识别已经参与到我们生活的方方面面。传统的身份识别方式(ID 卡、个人证件、门禁口令、银行卡账号密码等)都存在很大的危机：以账号密码作为个人身份认证方式的，很难保证账号密码不会被遗忘、丢失、盗取等；以证件作为个人身份认证方式的，很难保证证件不会被伪造；以口令作为个人身份认证方式的，很难保证口令不会被窃取。在这种情况下，更稳定可靠的生物识别技术开始得到快速发展。
生物识别技术[1-3]是指通过对人体生理特征的验证来实现个人身份准确识别的技术。由于人的生理特征与生俱来且各不相同，正好可以作为个人身份确认的识别方式，常用的生物识别方式有：指纹识别[4]，掌纹识别[5-6]，人脸识别，ECG 识别，虹膜识别，DNA 识别等。

本课题在观察从人脸训练集中随机抽样的一部分人脸图片时发现了一个现象：这些来自互联网的名人照片中有很大一部分拥有较好的光照、人脸角度和人脸清晰度，人脸质量较差的图片(既困难样本)只占少数部分。该现象发生的主要原因是：被公开到互联网的图片很多都是由专业人士采用专业相机拍摄的。这种现象将使得人脸识别模型无法在困难样本上得到充分的学习，导致人脸识别模型在无约束场景中不能很稳健地应对质量较差的人脸。
为了尝试解决这个问题，本课题引入了在线困难样本挖掘的方案。截止目前已经有很多实现方案，举例如下：
1)	focal loss：通过模型预测的概率pt，使用(1-Pt)来代表样本难分程度。可以理解为模型对某个样本预测属于其真实label的概率越高，则说明该样本对此模型比较容易学习，反之则难分。 
2)	《ScreenerNet: Learning Self-Paced Curriculum for Deep Neural Networks》论文提出一个附加网络来帮助主网络区分样本难易程度。
3)	《Fine-tuning Convolutional Neural Networks for Biomedical Image Analysis》论文通过对一张图像进行数据增强生成多张图像，然后使用模型预测每张图像的概率。根据多张相同label的增强图像的概率分布区分其样本难易程度。
4)	《OHEM: Training Region-based Object Detectors with Online Hard Example Mining》论文提出先使用模型输出概率，据此选出部分难分样本，然后根据这些样本，更新网络参数。
本课题最终选择参考最为简单巧妙的focal loss来实现在线困难样本挖掘。focal loss是通过改变交叉熵损失来实现的。叉熵损失属于softmax交叉熵损失的一部分，因此可以很方便地和arcface进行结合，其在二元分类场景中的公式为：
公式
在上面，y∈{±1}指定了地面实例类，p∈[0,1]是模型的标签y = 1的类的估计概率，有softmax(本课题中是arcface)计算得来。为了符号方便，我们定义了pt：
公式
这种损失的一个值得注意的特性：即使是容易分类的例子（p >0.5）也会带来较大的损失。这样将很容易掩盖困难样本。于是Tsung-Yi Lin等人在交叉熵损失中添加调制因子（1-pt）γ，可调聚焦参数γ≥0，此时公式将变为：
公式
其中α∈[0,1]加权因子，可以平衡了二分类中正负样本的重要性
我们注意到焦点损失的两个特性：
（1）当一个例子被错误分类并且pt很小时，调制因子接近1并且损失不受影响。 当pt→1时，因子变为0，并且对于良好分类的示例的损失是向下加权的。 
（2）聚焦参数γ平滑地调整简易示例被加权的速率。 当γ= 0时，FL是等效的。
不过Tsung-Yi Lin等人的研究场景是二分类问题，不能直接用于类似多分类问题的人脸识别训练中，于是本课题在保证focal loss形式不变的情况下进行了相应的改进，最后的公式为:
公式
Youyi 等
[32]
利用小波神经网络来构造人脸
识别系统，该方法将小波变换的多分辨特性引入到神经网络之中，很好的克服了较大噪
声下人脸识别困难的问题。史文樊
[33]
通过 Gabor 小波、PCA 算法、粗糙集等对 BP 神经
网络进行了一系列改进，最终提出粗糙集 BP 神经网络算法，该算法不仅提高了人脸识
别精度还对背景、表情等具有很好的鲁棒性。该类方法普遍具有较高的识别精度，是目
前性价比最高的一种方法，但该类方法在识别前需要进行网络训练，当网络权值取值不
当时，网络训练容易陷入局部最优，影响识别效果。
